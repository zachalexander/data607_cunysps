---
title: "DATA 607 - Final Project Proposal"
author: "Zach Alexander and Misha Kollontai"
date: "11/17/2019"
output: 
  html_document:
    toc: TRUE
---
```{r set-options, echo=FALSE, cache=FALSE}
options(width = 1200)
```

*** 

### Final Project Overview and Motivation

As the presidential election cycle starts to ramp up again, we thought it would be interesting to take a look back at the election data from 2016 in order to think more about potential factors that could affect the outcome of next year's vote. 
Labeled by [Politico as the "biggest upset in U.S. history"](https://www.politico.com/story/2016/11/election-results-2016-clinton-trump-231070), a large narrative about a "divided" America continued to develop in the days following the 2016 presidential election. Many would argue that this narrative continues to dominate current news headlines and will be an influential factor in the way candidates run their campaigns over the next 12 months.  

For our project, we are curious about what factors seem to “divide” America. We’ll explore questions such as:  

+ Which values are more characteristic of voters that decided to vote for Donald Trump in 2016?
+ Which are more representative of voters that voted for Hilary Clinton in 2016?
+ Are there trends in values on a statewide level? And if so, do they favor one candidate over the other? 
+ Were certain values more predictive than others in favoring votes for a particular candidate?

***

### Our Datasets

We’ll be utilizing two different datasets for this project.  

***

#### Dataset 1 -- 2016 Presidential Election Data

The first contains the 2016 presidential election results for every United States county, among other past election data. 

```{r, warning=FALSE, message=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(dplyr)
library(tidyr)
library(plyr)
library(knitr)
library(kableExtra)
```

```{r}
election_data <- read.csv('https://raw.githubusercontent.com/zachalexander/data607_cunysps/master/FinalProject/election_data.csv')
kable(head(election_data, n = 15L), align = rep('c', 5)) %>% 
  kable_styling(bootstrap_options = c("striped", "responsive", "condensed"), full_width = FALSE) %>% 
  kableExtra::scroll_box(width = "100%", height = "500px")
```

*** 

The dataset was found on GitHub, here: https://github.com/tonmcg/US_County_Level_Election_Results_08-16  

**Information about this dataset:** The 2016 election results were obtained from [Townhall.com](https://www.townhall.com) by utilizing a web-scraping package -- `beautifulsoup`. This Python package is referenced in the GitHub readme file of the user above. `Beautifulsoup` is an HTML parser that assists in scraping data from websites. In this case, the GitHub user located the published election results [here](https://townhall.com/election/2016/president/), and due to it's easy-to-scrape html table format, was able to obtain the results quite easily using this package. Websites like Townhall.com have designated data teams that help produce the real-time election results on the night of the election.  

***

#### Dataset 2 -- Public Religion Research Institute (PRRI)

The second dataset that we’ll work with contains data related to values, with a respondent identifier that captures their state of residence – which we can use to connect to our election results. This dataset was found on the [Public Religion Research Institute (PRRI)](https://www.prri.org/data-vault/) website and contains a large number of questions related to values ranging from respondent’s views on immigration, gun control laws, health care, and much more. 

**Information about this dataset:** This survey was completely designed and conducted by PRRI. Their website states that it is the "eighth annual multi-issue survey of it's kind".  

**Survey Methodology**  

+ The survey was conducted between October 18th and October 30th, 2017.
+ Data collection was based on stratified, single-stage, random-digit-dialing (RDD) sampling of landline telephone households and randomly generated cell phone numbers.
+ In the end, they were able to survey 2,019 individuals (810 landline and 1,209 cell phone)
+ The sample represents responses from adults 18 years or older living in the United States.

***

### Data Wrangling

***

#### Reading data files from Github

```{r, warning=FALSE, message=FALSE, echo=TRUE}
library(haven)
spss_file <- file.path('https://github.com/zachalexander/data607_cunysps/blob/master/FinalProject/PRRI-2017-American-Values-Survey.sav?raw=true')
avs <- read_sav(spss_file)
kable(head(avs, n = 15L), align = rep('c', 5)) %>% 
  kable_styling(bootstrap_options = c("striped", "responsive", "condensed"), full_width = FALSE) %>% 
  kableExtra::scroll_box(width = "100%", height = "500px")
```

*** 

#### Subsetting the data

To start we subset the election data and select columns that are relevant to the 2016 election, including the state column and the election totals for Republicans, Democrats, and Independents by county. Then, we create a `total` column that sums the total votes per county. Next, we use the group_by() and summarise_all() functions to group and sum the votes by state. Now, we have a data frame with the summed votes per state, with each state only being one line. Finally, we add a percentage column to get the percent of voters that voted for Donald Trump broken down by each state.  

```{r}
library(dplyr)
Trump_sub<- election_data[,c(2,5,6,7)]
Trump_sub$total16 <- Trump_sub$trump16 + Trump_sub$clinton16 + Trump_sub$otherpres16
Trump_map <- Trump_sub %>% group_by(state) %>% summarise_all(sum)
Trump_map$trump_per <- Trump_map$trump16/Trump_map$total16
```

For our next analyses and plots, we'll want to load in a few mapping packages, as well as the tidyverse package for more data wrangling.  

```{r plot trumps votes, message=FALSE, warning=FALSE}
library(tidyverse)
library(sf)
library(maps)
library(RColorBrewer)
```

#### Misha - definitely edit this up if you'd like!
In order to create our first map, we needed to use the `maps` package to help load in the necessary data that will allow us to create a map of the United States. We were able to load in the proper geometries to draw the state boundaries, as well as project the map to the correct coordinate plane. Then, we needed to subset our election data a bit more to remove the vote totals for Alaska and Hawaii, since there was a very low number of respondents to the American Values Survey from these states, we felt that any analyses and comparisons would not be representative of these locations.  

```{r}
library(tools)
states <- st_as_sf(map("state", plot = FALSE, fill = TRUE))
states$ID <- toTitleCase(states$ID)
USA_votes <- Trump_map[which(Trump_map$state != "Alaska" & Trump_map$state != "Hawaii"),]
states$trump_per <- USA_votes$trump_per

for(i in 1:length(states$trump_per)){
  if(states$trump_per[i]-0.5>0.05){
    states$color[i] <- "1 - Greater than 55% voted for Trump"
  }
  if(states$trump_per[i]-0.5< 0.05 & states$trump_per[i]- 0.5 >0){
    states$color[i] <- "2 - Between 50% and 55% voted for Trump"
  }
  if(states$trump_per[i]-0.5> (-0.05) & states$trump_per[i]-0.5<0){
    states$color[i] <- "3 - Between 45 and 50% voted for Trump"
  }
  if(states$trump_per[i]-0.5< (-0.05)){
    states$color[i] <- "4 - Less than 45% voted for Trump"
  }
}
            
```


***
### 2016 Presidential Election Data
***

#### Here's the Election Data presented in two ways: {.tabset .tabset-pills}

##### Percentages

After getting the data into a state where we can start to plot out the percentages, we decided to use `ggplot` to create a map to show the percentage of voters that voted for Donald Trump in the 2016 election. In order to show differences across states, we decided to create delta values of the percent votes for Donald Trump from 50%. 

```{r, echo=FALSE}
ggplot(data = states) +
  ggtitle("Percentage of 2016 Trump Votes Delta from 50%") +
  geom_sf(aes(fill = states$trump_per-0.5)) +
  scale_fill_distiller(palette ="RdBu", limits = c(-0.5,0.5)) +
  labs(fill = "Percentage") +
  coord_sf(xlim = c(-125,-65), ylim = c(25,50), expand = FALSE) + 
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "right",
    legend.direction = "vertical",
    legend.justification = "center",
    axis.text.x = element_blank(),
    axis.ticks = element_blank(),
    axis.text.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )

```


##### Broader Trend

In order to show differences across states, we decided to show a breakdown based on percent groupings of total votes for Donald Trump. States that are more red had a larger percentage of Trump voters, while states that are more blue had a smaller percentage of Trump voters.  


```{r plot_state_votes, echo=FALSE}
mycols <- c("#CF0F0F", "#CF9594", "#95A7C2", "#30659B")

ggplot(data = states) +
  ggtitle("2016 Election - Percentage of Votes for Trump By State") +
  geom_sf(aes(fill = states$color)) +
  scale_fill_manual(values = mycols) +
  coord_sf(xlim = c(-125,-65), ylim = c(25,50), expand = FALSE) + 
  theme(
    plot.title = element_text(hjust = 0.5),
    legend.position = "bottom",
    legend.direction = "vertical",
    legend.justification = "center",
    legend.title = element_blank(),
    axis.text.x = element_blank(),
    axis.ticks = element_blank(),
    axis.text.y = element_blank(),
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank()
  )
```

####

***
From these maps, we can see that the percentage of votes per state varied quite drastically across different states and regions of the United States. In the next phase, we thought it would be interesting to see if certain values can be attributed to these differences in voting percentages for Donald Trump.  


***

### American Values Survey

***

Next, we needed to do some data wrangling in order to isolate the responses that we will use later for data analysis and mapping. We decided to create a for loop to create multiple data frames that have the state of the respondent as well as their numerical answer. Additionally, we decided to subset these datasets to only include definitive answers. In other words, we removed responses that indicated "Don't know" or "Refuse to answer".  

```{r calculate_state_values}
question_list <- c("q17a", "q17b", "q17c", "q17d", "q17e", "q17f", "q17g", "q17h")
df_list <- c("Temp_df_a", "Temp_df_b", "Temp_df_c", "Temp_df_d", "Temp_df_e", "Temp_df_f", "Temp_df_g", "Temp_df_h")
q_num <- c(90,92,91,93,94,95,96,97)

for(i in 1:length(q_num)){
 assign(df_list[i], avs[which(avs[[paste(question_list[i])]]< 5), c(4, q_num[i])])
}
```

***

Now that the data has been tidy'd into temporary dataframes and cleaned up, we can use some of the tidyverse functions in order to group and calculate average response values for each question by state. We can do this by using the `lapply()`, `group_by()`, and `summarise_all()` functions.  

```{r}
df_state_list <- c("state_q17a", "state_q17b", "state_q17c", "state_q17d", "state_q17e", "state_q17f", "state_q17g", "state_q17h")
dfs <- list(Temp_df_a, Temp_df_b, Temp_df_c, Temp_df_d, Temp_df_e, Temp_df_f, Temp_df_g, Temp_df_h)

grouped_data <- lapply(dfs, function(x){ x %>% group_by(state) %>% summarise_all(mean)})

for(i in 1:length(grouped_data)){
  assign(df_state_list[i], as.data.frame(grouped_data[[i]]))
}
```


Next, we merged all of the answers to question #17 into one dataframe in order to set up our file for mapping. By then joining these answers to the coordinate and geometric information, we were then able to create some maps of answer responses to these questions broken out by U.S. state.  

```{r, message=FALSE, warning=FALSE}
library(openintro)
q17_df <- Reduce(function(x, y) merge(x, y, all=TRUE), list(state_q17a, state_q17b, state_q17c, state_q17d, state_q17e, state_q17f, state_q17g, state_q17h))

q17_df <- q17_df[which(q17_df$state != "HI" & q17_df$state != "AK"),]
q17_df$state <- abbr2state(q17_df$state)
names(q17_df) <- c("ID", "q17a", "q17b", "q17c", "q17d", "q17e", "q17f", "q17g", "q17h")

states <- merge(states,q17_df,by="ID")
```

```{r generic state plot, echo = FALSE}
state_map <- ggplot(data = states) +
  theme(
    plot.title = element_text(hjust = 0.5)
  )
```

***

#### Interpretation of American Values Survey Questions

So after all of the data wrangling we performed, how can we interpret it? We decided to take a look at a few questions that seemed to be pertinent and relevant topics to see if they also varied across states. The first question we looked at was Question 17:  

***

#### Question 17 -- Do you strongly favor, favor, oppose or strongly oppose the following? {.tabset .tabset-pills}


##### A

```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Allowing gay and lesbian couples to marry legally") +
  geom_sf(aes(fill = -(states$q17a-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

##### B

```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Allow business owner to refuse products/services to gay/lesbian people") +
  geom_sf(aes(fill = -(states$q17b-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

##### C

```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Laws protecting LGBTQ in jobs, housing, etc.") +
  geom_sf(aes(fill = -(states$q17c-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

##### D
  
```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Build the Wall") +
  geom_sf(aes(fill = -(states$q17d-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

##### E
  
```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Muslim Ban") +
  geom_sf(aes(fill = -(states$q17e-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

##### F

```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("DACA through army or college") +
  geom_sf(aes(fill = -(states$q17f-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

##### G
  
```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Prevent refugees from entering USA") +
  geom_sf(aes(fill = -(states$q17g-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

##### H

```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Withdraw from Iran nuclear deal") +
  geom_sf(aes(fill = -(states$q17h-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

####

***

After creating maps for each component of question #17, we could visibly see that some items seemed to draw starker contrasts across states than others. For instance, there seemed to generally be pretty broad support in favor of allowing DACA recipients brought to the U.S. as children to gain legal resident status if they attend college or join the military. However, there seemed to be more disagreement across states for support over withdrawing from the nuclear agreement with Iran or temporarily preventing people from some majority Muslim countries from entering the United States.  

At this point we decided to build our first regression model using the parts of question 17 as the variables. 

```{r regression1}
elec_regr1 <- lm(trump_per ~  q17a + q17b + q17c + q17d + q17e + q17f + q17g + q17h , data = states)
summary(elec_regr1)
```

The first model resulted in an $R^{2}$ value of 0.529. Not too shabby for a first pass, but something that could hopefully be improved on. Before moving on to additional variables, we decided to apply some backward elimination to reduce our focus. This resulted in the following model with a slightly lower $R^{2}$ of 0.5173, but fewer variables and a higher adjusted $R^{2}$.

```{r regression2}
elec_regr2 <- lm(trump_per ~  q17c + q17d + q17e + q17f + q17h , data = states)
summary(elec_regr2)
```

***
At this point we decided to expand our field of variables and look at more questions. The next step was scrubbing the data from questions 22, 24 and 25 and incorporating them into our regression model. 

#### Question 22 -- Now as I read a few statements please tell me whether you completely agree, mostly agree, mostly disagree or completely disagree with each one? {.tabset .tabset-pills}


```{r calculate_state_values_q6_22_24_25, echo = FALSE}
df_list_2 <- c("Temp_df_i", "Temp_df_j", "Temp_df_k", "Temp_df_l", "Temp_df_m", "Temp_df_n", "Temp_df_o")
q_num <- c(104,105,106,107,108,109,110)

for(i in 1:length(q_num)){
 assign(df_list_2[i], avs[which(avs[[paste(question_list[i])]]< 5), c(4, q_num[i])])
}

question_list <- c("q24", "q25")
df_list_3 <- c("Temp_df_p", "Temp_df_q")
q_num <- c(112,114)

for(i in 1:length(q_num)){
 assign(df_list_3[i], avs[which(avs[[paste(question_list[i])]]< 3), c(4, q_num[i])])
}

question_list <- c("q6a", "q6b", "q6c", "q6d", "q6e", "q6f", "q20", "q21")
df_list_4 <- c("Temp_df_r", "Temp_df_s", "Temp_df_t", "Temp_df_u", "Temp_df_v", "Temp_df_w", "Temp_df_x", "Temp_df_y")
q_num <- c(65,66,67,68,69,70,100,102)

for (i in 1:length(q_num)){
  assign(df_list_4[i], avs[which(avs[[paste(question_list[i])]] < 4), c(4,q_num[i])])
}
```

```{r, echo = FALSE}

df_state_list <- c("state_q22a", "state_q22b", "state_q22c", "state_q22d", "state_q22e", "state_q22f", "state_q22g", "state_q24", "state_q25", "state_q6a", "state_q6b", "state_q6c", "state_q6d", "state_q6e", "state_q6f", "state_q20", "state_q21")
dfs <- list(Temp_df_i, Temp_df_j, Temp_df_k, Temp_df_l, Temp_df_m, Temp_df_n, Temp_df_o, Temp_df_p, Temp_df_q, Temp_df_r, Temp_df_s, Temp_df_t, Temp_df_u, Temp_df_v, Temp_df_w, Temp_df_x, Temp_df_y)

grouped_data <- lapply(dfs, function(x){ x %>% group_by(state) %>% summarise_all(mean)})

for(i in 1:length(grouped_data)){
  assign(df_state_list[i], as.data.frame(grouped_data[[i]]))
}
```


```{r}
library(openintro)
q22_df <- Reduce(function(x, y) merge(x, y, all=TRUE), list(state_q22a, state_q22b, state_q22c, state_q22d, state_q22e, state_q22f, state_q22g, state_q24, state_q25, state_q6a, state_q6b, state_q6c, state_q6d, state_q6e, state_q6f, state_q20, state_q21))

q22_df <- q22_df[which(q22_df$state != "HI" & q22_df$state != "AK"),]
q22_df$state <- abbr2state(q22_df$state)
names(q22_df) <- c("ID", "q22a", "q22b", "q22c", "q22d", "q22e", "q22f", "q22g", "q24", "q25", "q6a", "q6b", "q6c", "q6d", "q6e", "q6f", "q20", "q21")

states <- merge(states,q22_df,by="ID")
```


##### A

```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("The severity of recent natural\ndisasters is evidence of climate change\n") +
  geom_sf(aes(fill = -(states$q22a-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

##### B

```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Because things have gotten so far off track in this country,\nwe need a leader who is willing to break some rules\nif that’s what it takes to set things right") +
  geom_sf(aes(fill = -(states$q22b-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

##### C

```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("In the past, America’s leaders have been too focused \n on helping other nations at the expense of our own country\n") +
  geom_sf(aes(fill = -(states$q22c-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

##### D
  
```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle(" It bothers me when I come in contact with\nimmigrants who speak little or no English\n") +
  geom_sf(aes(fill = -(states$q22d-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

##### E
  
```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("\nAmerica today sets a good moral example for the world\n") +
  geom_sf(aes(fill = -(states$q22e-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

##### F

```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Professional athletes should be required to stand\nduring the national anthem at sporting events\n") +
  geom_sf(aes(fill = -(states$q22f-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

##### G
  
```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("The government should guarantee health insurance\nfor all citizens, even if it means raising taxes\n") +
  geom_sf(aes(fill = -(states$q22g-2.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-1.5,1.5))
```

####

***

Additionally, we created maps for each component of question #22, where we could also visibly see that some items in this question seemed to draw starker contrasts across states than others. For instance, there seemed to generally be pretty broad support that people were not bothered when they come in contact with immigrants who speak little or no English. However, there seemed to be more disagreement across states for attribution of the severity of recent natural disasters to global climate change or whether professional athletes should be required to stand during the national anthem at sporting events.  

These responses were also helpful when building out our regression models later on in our investigation.  

***

#### Question 24 -- Do you think recent stories about women being sexually harassed and assaulted in the workplace are isolated incidents or are they part of a broader pattern of how women are often treated?

```{r, echo = FALSE, fig.align = 'center'}
state_map +
  geom_sf(aes(fill = -(states$q24-1.5))) +
  labs(fill = "Support") +
  scale_fill_gradient2(limits = c(-0.5,0.5))
```

Once we'd aggregated the data from these questions, we decided to take a look at an expanded regression model incorporating our new variables. 

```{r regression3}
elec_regr3 <- lm(trump_per ~  q17c + q17d + q17e + q17f + q17h + q22a + q22b + q22c + q22d + q22e + q22f + q24 + q25, data = states)
summary(elec_regr3)
```

Adding our 8 new variables yielded a slight increase in the $R^{2}$ value (about 0.09), but many of the variables show high p-values and can therefore be eliminated from the model without significant losses to the $R^{2}$ value. Our backward elimination process here led to us removing all of the responses to the parts of question 22. It appears that the responses to the parts of that question were not strong predictors of a vote for Trump in 2016. 

```{r regression4}
elec_regr4 <- lm(trump_per ~  q17c + q17d + q17e + q24 + q25, data = states)
summary(elec_regr4)
```

Having looked over the Survey, we decided to incorporate the responses to question 6 into our model as well. Below are plots of the responses organized by state.

#### Question 6 -- Should **the following topic** be the highest priority, high but not the highest, or a lower priority? {.tabset .tabset-pills}

##### A

```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Reforming the nation's immigration system") +
  geom_sf(aes(fill = -(states$q6a-2))) +
  labs(fill = "Priority") +
  scale_fill_gradient2(limits = c(-1,1))
```

##### B

```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Enacting stricter gun control laws") +
  geom_sf(aes(fill = -(states$q6b-2))) +
  labs(fill = "Priority") +
  scale_fill_gradient2(limits = c(-1,1))
```

##### C

```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Reducing health care costs") +
  geom_sf(aes(fill = -(states$q6c-2))) +
  labs(fill = "Priority") +
  scale_fill_gradient2(limits = c(-1,1))
```

##### D
  
```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Reducing the budget deficit") +
  geom_sf(aes(fill = -(states$q6d-2))) +
  labs(fill = "Priority") +
  scale_fill_gradient2(limits = c(-1,1))
```

##### E
  
```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Changing the federal income tax system to make it more fair") +
  geom_sf(aes(fill = -(states$q6e-2))) +
  labs(fill = "Priority") +
  scale_fill_gradient2(limits = c(-1,1))
```

##### F

```{r, echo = FALSE, fig.align = 'center'}
state_map +
  ggtitle("Enacting legislation to address climate change") +
  geom_sf(aes(fill = -(states$q6f-2))) +
  labs(fill = "Priority") +
  scale_fill_gradient2(limits = c(-1,1))
```

####

This next regression model incorporated all of the responses to questions 6a-f.

```{r regression5}
elec_regr5 <- lm(trump_per ~  q17c + q17d + q17e + q24 + q25 + q6a + q6b + q6c + q6d + q6e + q6f, data = states)
summary(elec_regr5)
```

Finally, a respectable $R^{2}$ value! Let's clean it up a little by removing some of the less impactful variables...

```{r regression6}
elec_regr6 <- lm(trump_per ~  q17c + q17d + q24 + q6b + q6c + q6d + q6e, data = states)
summary(elec_regr6)
```

```{r}
require(ggiraph)
require(ggiraphExtra)
require(plyr)
require(tidyverse)

# map_data <- USA_votes %>% select(state, trump_per)

# write.csv(map_data, 'C:/Users/zalexander/Desktop/election_data.csv')

states <- states %>% select(ID, trump_per, q17a, q17b, q17d, q17f, q22e, q22f, q6b, q6c, q6e, q6f, q20, q21)


for(i in 1:length(states$ID)){
  states$model[i] <- 0.83630 + 
    (0.07863 * states$q17a[i]) + 
    (-0.08399 * states$q17b[i]) + 
    (-0.14377 * states$q17d[i]) + 
    (0.09759 * states$q17f[i]) + 
    (-0.06089 * states$q22e[i]) + 
    (0.07426 * states$q22f[i]) + 
    (0.14610 * states$q6b[i]) +
    (-0.12655 * states$q6c[i]) +
    (-0.08417 * states$q6e[i]) +
    (-0.04930 * states$q6f[i]) +
    (-0.41984 * states$q20[i]) +
    (0.40825 * states$q21[i])
  
  states$diff[i] <- states$model[i] - states$trump_per[i]
}

model <- lm(formula = trump_per ~ q17a + q17b + q17d + q17f+ q22e+ q22f+ q6b+ q6c+ q6e+ q6f + q20+ q21, data = states)
summary(model)
step(model, direction = "both", trace=FALSE ) 

model <- lm(formula = trump_per ~ q17a + q17b + q17d + q17f+ q22e+ q22f+ q6b+ q6c+ q6e + q20+ q21, data = states)
summary(model)

for(i in 1:length(states$ID)){
  states$model_two[i] <- 0.41340 + 
    (0.10186 * states$q17a[i]) + 
    (-0.08226 * states$q17b[i]) + 
    (-0.10941 * states$q17d[i]) + 
    (0.11533 * states$q17f[i]) + 
    (-0.06833 * states$q22e[i]) + 
    (0.07729 * states$q22f[i]) + 
    (0.16358 * states$q6b[i]) +
    (-0.11869 * states$q6c[i]) +
    (-0.08723 * states$q6e[i]) +
    (-0.28826 * states$q20[i]) +
    (0.36884 * states$q21[i])
  
  states$diff_two[i] <- states$model_two[i] - states$trump_per[i]
}

states_out <- states %>% 
  filter(ID != "California" & ID != "Maryland" & ID != "Oklahoma" & ID != "Montana" & ID != "North Dakota")

model_three <- lm(formula = trump_per ~ q17a + q17b + q17d + q17f+ q22e+ q22f+ q6b+ q6c+ q6e + q20+ q21, data = states_out)
summary(model_three)

for(i in 1:length(states_out$ID)){
  states_out$model_three[i] <- 0.35615 + 
    (0.08077 * states_out$q17a[i]) + 
    (-0.07477 * states_out$q17b[i]) + 
    (-0.12467 * states_out$q17d[i]) + 
    (0.12577 * states_out$q17f[i]) + 
    (-0.08823 * states_out$q22e[i]) + 
    (0.06634 * states_out$q22f[i]) + 
    (0.15742 * states_out$q6b[i]) +
    (-0.09137 * states_out$q6c[i]) +
    (-0.06588 * states_out$q6e[i]) +
    (-0.26037 * states_out$q20[i]) +
    (0.42384 * states_out$q21[i])
  
  states_out$diff_three[i] <- states_out$model_three[i] - states_out$trump_per[i]
}

model_data <- as.data.frame(states_out) %>% select(ID, trump_per, model_three, diff_three)

write.csv(model_data, 'C:/Users/zalexander/Desktop/model_data.csv')
```



