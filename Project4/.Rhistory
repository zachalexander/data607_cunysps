knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(stringr)
library(SnowballC)
library(tidyverse)
library(stringi)
library(corpus)
install.packages('corpus')
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(stringr)
library(SnowballC)
library(tidyverse)
library(stringi)
library(corpus)
spam <- VCorpus(DirSource(directory = '/Users/zdalexander/Desktop/grad_school/data_607_cunysps/data607_cunysps/Project4/spam'))
spam <- VCorpus(DirSource(directory = 'C:/Users/zdalexander/data607_cunysps/Project4/spam'))
spam <- VCorpus(DirSource(directory = 'C:/Users/zalexander/data607_cunysps/Project4/spam'))
spam <- VCorpus(DirSource(directory = 'C:/Users/zalexander/Desktop/data607_cunysps/Project4/spam'))
for(i in 1:length(spam)){
as_corpus_text(iconv(content(spam[[i]]), "Latin1", "UTF-8", sub = ""))
meta(spam[[i]], "email_group") <- "spam"
}
ham <- VCorpus(DirSource(directory = 'C:/Users/zalexander/Desktop/data607_cunysps/Project4/easy_ham'))
ham
for(i in 1:length(ham)){
as_corpus_text(iconv(content(ham[[i]]), "Latin1", "UTF-8", sub = ""))
meta(ham[[i]], "email_group") <- "ham"
}
all_emails <- c(spam, ham)
all_emails = tm_map(all_emails, removeNumbers)
all_emails = tm_map(all_emails, removePunctuation)
all_emails = tm_map(all_emails, stripWhitespace)
## not working
all_emails <- tm_map(all_emails, removeWords, stopwords("english"))
all_emails <- tm_map(all_emails, content_transformer(tolower))
all_emails[[2]]$content
analysis <- all_emails %>%
meta(tag = "email_group") %>%
unlist() %>%
table()
analysis
temp <- tempfile()
download.file("https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2",temp)
data <- read.table(unz(temp, "a1.dat"))
temp <- tempfile()
download.file("https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2", temp)
data <- read.table(unz(temp, "a1.dat"))
temp <- tempfile()
download.file("https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2", temp)
data <- read.table(untar(temp, "a1.dat"), list = TRUE)
temp <- tempfile()
download.file("https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2", temp)
data <- read.table(untar(temp, "a1.dat"))
temp <- tempfile()
download.file("https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2", temp)
data <- read.table(untar(temp))
temp <- download.file("https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2")
temp <- download.file(destfile = "https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2")
url <- "https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2"
temp <- download.file(url, destfile = "tmp.tar.bz2")
data <- read.table(untar(temp))
url <- "https://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2"
download.file(url, destfile = "tmp.tar.bz2")
data <- read.table(untar("tmp.tar.bz2"))
?wordcloud
install.packages('wordcloud')
?wordcloud
?wordcloud()
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(stringr)
library(SnowballC)
library(tidyverse)
library(stringi)
library(corpus)
library(wordcloud)
library(e1071)
download.file(url = "http://spamassassin.apache.org/old/publiccorpus/20021010_easy_ham.tar.bz2", destfile = "20021010_easy_ham.tar.bz2")
untar("20021010_easy_ham.tar.bz2",compressed = "bzip2")
ham_emails = list.files(path = "easy_ham",full.names = TRUE)
download.file(url = "http://spamassassin.apache.org/old/publiccorpus/20030228_spam_2.tar.bz2", destfile = "20030228_spam_2.tar.bz2")
untar("20030228_spam_2.tar.bz2", compressed = "bzip2")
spam_emails = list.files(path = "spam_2", full.names = TRUE)
spam_emails_list <- NA
for (i in 1:length(spam_emails)){
email_text1 <- readLines(spam_emails[i])
email_list1 <- list(paste(email_text1, collapse = "\n"))
spam_emails_list <- c(spam_emails_list, email_list1)
}
ham_emails_list <- NA
for (i in 1:length(ham_emails)){
email_text <- readLines(ham_emails[i])
email_list <- list(paste(email_text, collapse = "\n"))
ham_emails_list <- c(ham_emails_list, email_list)
}
# removing blank first item in lists
ham_emails_list <- ham_emails_list[-1]
spam_emails_list <- spam_emails_list[-1]
ham_df <- data.frame(unlist(ham_emails_list))
ham_df$email_group <- 'ham'
ham_df <- ham_df %>%
rename("email_text" = unlist.ham_emails_list.)
spam_df <- data.frame(unlist(spam_emails_list))
spam_df$email_group <- 'spam'
spam_df <- spam_df %>%
rename("email_text" = unlist.spam_emails_list.)
full_email_df <- rbind(ham_df, spam_df)
spam_df$email_text <- iconv(spam_df$email_text, "ASCII", "UTF-8", sub="byte")
# spam word cloud
suppressWarnings(wordcloud(spam_freq$word, spam_freq$freq, min.freq=550))
# spam_df$email_text <- iconv(spam_df$email_text, "ASCII", "UTF-8", sub="byte")
# ham_df$email_text <- iconv(ham_df$email_text, "ASCII", "UTF-8", sub="byte")
# full_email_df$email_text <- iconv(full_email_df$email_text, "ASCII", "UTF-8", sub="byte")
spamCorpus <- Corpus(VectorSource(spam_df$email_text))
hamCorpus <- Corpus(VectorSource(ham_df$email_text))
spam_hamCorpus <- Corpus(VectorSource(full_email_df$email_text))
spamCorpus <- tm_map(spamCorpus, removeNumbers)
spamCorpus <- tm_map(spamCorpus, removePunctuation)
spamCorpus <- tm_map(spamCorpus, stripWhitespace)
spamCorpus <- tm_map(spamCorpus, removeWords, stopwords())
spamCorpus <- tm_map(spamCorpus, content_transformer(tolower))
hamCorpus <- tm_map(hamCorpus, removeNumbers)
hamCorpus <- tm_map(hamCorpus, removePunctuation)
hamCorpus <- tm_map(hamCorpus, stripWhitespace)
hamCorpus <- tm_map(hamCorpus, removeWords, stopwords())
hamCorpus <- tm_map(hamCorpus, content_transformer(tolower))
spam_hamCorpus <- tm_map(spam_hamCorpus, removeNumbers)
spam_hamCorpus <- tm_map(spam_hamCorpus, removePunctuation)
spam_hamCorpus <- tm_map(spam_hamCorpus, stripWhitespace)
spam_hamCorpus <- tm_map(spam_hamCorpus, removeWords, stopwords())
spam_hamCorpus <- tm_map(spam_hamCorpus, content_transformer(tolower))
spamDTM <- TermDocumentMatrix(spamCorpus)
hamDTM <- TermDocumentMatrix(hamCorpus)
spam_hamDTM <- TermDocumentMatrix(spam_hamCorpus)
spamDTM_matrix <- as.matrix(spamDTM)
spam_v <- sort(rowSums(spamDTM_matrix),decreasing=TRUE)
spam_freq <- data.frame(word = names(spam_v),freq=spam_v)
hamDTM_matrix <- as.matrix(hamDTM)
ham_v <- sort(rowSums(hamDTM_matrix),decreasing=TRUE)
ham_freq <- data.frame(word = names(ham_v),freq=ham_v)
# spam word cloud
suppressWarnings(wordcloud(spam_freq$word, spam_freq$freq, min.freq=550))
# ham word cloud
suppressWarnings(wordcloud(ham_freq$word, ham_freq$freq, min.freq=850, scale=c(1.5,1)))
View(full_email_df)
full_email_tokens = full_email_df %>%
unnest_tokens(word, text) %>%
filter(!str_detect(word, "^[0-9]*$")) %>%
anti_join(stop_words) %>%
mutate(word = wordStem(word))
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(stringr)
library(SnowballC)
library(tidyverse)
library(stringi)
library(corpus)
library(wordcloud)
library(e1071)
library(dplyr)
library(tidytext)
install.packages('tidytext')
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(stringr)
library(SnowballC)
library(tidyverse)
library(stringi)
library(corpus)
library(wordcloud)
library(e1071)
library(dplyr)
library(tidytext)
library(caret)
install.packages('caret')
knitr::opts_chunk$set(echo = TRUE)
library(tm)
library(stringr)
library(SnowballC)
library(tidyverse)
library(stringi)
library(corpus)
library(wordcloud)
library(e1071)
library(dplyr)
library(tidytext)
library(caret)
library(DT)
full_email_tokens = full_email_df %>%
unnest_tokens(word, text) %>%
filter(!str_detect(word, "^[0-9]*$")) %>%
anti_join(stop_words) %>%
mutate(word = wordStem(word))
full_email_tokens = full_email_df %>%
unnest_tokens(word, text) %>%
filter(!str_detect(word, "^[0-9]*$")) %>%
anti_join(stop_words) %>%
mutate(word = wordStem(word))
full_email_tokens = full_email_df$email_text %>%
unnest_tokens(word, text) %>%
filter(!str_detect(word, "^[0-9]*$")) %>%
anti_join(stop_words) %>%
mutate(word = wordStem(word))
full_email_tokens = full_email_df %>%
unnest_tokens(word, email_text) %>%
filter(!str_detect(word, "^[0-9]*$")) %>%
anti_join(stop_words) %>%
mutate(word = wordStem(word))
datatable(full_email_df)
hamspam_tokens = full_email_df %>%
unnest_tokens(word,email_text) %>%
filter(!str_detect(word, "^[0-9]*$")) %>%
anti_join(stop_words) %>%
mutate(word = wordStem(word))
hamspam_tokens = full_email_df$email_text %>%
unnest_tokens(word,email_text) %>%
filter(!str_detect(word, "^[0-9]*$")) %>%
anti_join(stop_words) %>%
mutate(word = wordStem(word))
hamspam_tokens = unnest_tokens(word,full_email_df$email_text) %>%
filter(!str_detect(word, "^[0-9]*$")) %>%
anti_join(stop_words) %>%
mutate(word = wordStem(word))
hamspam_tokens = full_email_df %>%
unnest_tokens(word,full_email_df$email_text) %>%
filter(!str_detect(word, "^[0-9]*$")) %>%
anti_join(stop_words) %>%
mutate(word = wordStem(word))
?unnest_tokens
test <-  unnest_tokens(word,full_email_df$email_text)
test <-  unnest_tokens(full_email_df$email_text)
test <- unnest_tokens(full_email_df$email_text)
test <- unnest_tokens(as.character(full_email_df$email_text))
test <- unnest_tokens(full_email_df)
test <- unnest_tokens(spam_emails_list)
repairs_data <- read.csv('J:/Help Center/Zach-Housing-Resource-Center/Excel_outputs/repairs-summary_10-07-2019.csv')
View(repairs_data)
repair_subset <- repairs_data %>%
filter(str_detect(Case.Note, '\\.*foll*.*') |
str_detect(Case.Note, '\\.*leak*.*') |
str_detect(Case.Note, '\\.*paint*.*')|
str_detect(Case.Note, '\\.*plaster*.*')|
str_detect(Case.Note, '\\.*cabinet*.*')|
str_detect(Case.Note, '\\.*radiat*.*')|
str_detect(Case.Note, '\\.*window*.*')|
str_detect(Case.Note, '\\.*mold*.*')|
str_detect(Case.Note, '\\.*door*.*')|
str_detect(Case.Note, '\\.*refrigerat*.*')|
str_detect(Case.Note, '\\.*exterminat*.*')
) %>%
mutate(Compliance.Note.Date = as.Date(as.Date(Compliance.Note.Date, format="%d-%b-%y")), format="%b-%d-%Y") %>%
select(Full.Name, Development.Name, Compliance.Note.Date, Case.Note, Note_category) %>%
arrange(Full.Name, Compliance.Note.Date)
View(repair_subset)
repair_subset <- repair_subset[3:nrow(repair_subset),]
repair_subset$ncount <- NA
repair_subset$ncount[1] <- 1
for (i in 2:length(repair_subset$Full.Name)) {
if(repair_subset$Full.Name[i] == repair_subset$Full.Name[i-1]){
repair_subset$ncount[i] <- repair_subset$ncount[i-1] + 1
} else {
repair_subset$ncount[i] <- 1
}
}
repair_subset <- repair_subset %>%
select(Full.Name, Development.Name, ncount, Compliance.Note.Date, Case.Note, Note_category) %>%
mutate(Case.Note = tolower(Case.Note)) %>%
mutate(Case.Note = str_replace_all(Case.Note, 'follow\\s?\\-?\\s?up?:?;?\\s?-?\\s?,?\\s?', ''))
repair_subset$compare <- NA
repair_subset$compare[1] <- NA
for (i in 2:length(repair_subset$Full.Name)) {
if(repair_subset$ncount[i] != 1){
repair_subset$compare[i] <- levenshteinSim(repair_subset$Case.Note[i-1], repair_subset$Case.Note[i])
} else {
repair_subset$compare[i] <- NA
}
}
# repair_subset <- repair_subset %>%
#   mutate(Note = paste0('(', Compliance.Note.Date, ') : ', Case.Note, ' [', format(compare, digits = 2), ']')) %>%
#   select(Full.Name, Development.Name, ncount, Note) %>%
#   spread(ncount, Note)
for (i in 2:length(repair_subset$Full.Name)) {
if(repair_subset$ncount[i] != 1){
repair_subset$compare[i] <- levenshteinSim(repair_subset$Case.Note[i-1], repair_subset$Case.Note[i])
} else {
repair_subset$compare[i] <- NA
}
}
library(dplyr)
library(tidyr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(scales)
library(stringr)
library(lubridate)
library(tidyverse)
library(RecordLinkage)
for (i in 2:length(repair_subset$Full.Name)) {
if(repair_subset$ncount[i] != 1){
repair_subset$compare[i] <- levenshteinSim(repair_subset$Case.Note[i-1], repair_subset$Case.Note[i])
} else {
repair_subset$compare[i] <- NA
}
}
repair_subset <- repair_subset %>%
mutate(Note = paste0('(', Compliance.Note.Date, ') : ', Case.Note, ' [', format(compare, digits = 2), ']')) %>%
select(Full.Name, Development.Name, ncount, Note) %>%
spread(ncount, Note)
library(dplyr)
library(tidyr)
library(ggplot2)
library(knitr)
library(kableExtra)
library(scales)
library(stringr)
library(lubridate)
library(tidyverse)
library(RecordLinkage)
repairs_data <- read.csv('J:/Help Center/Zach-Housing-Resource-Center/Excel_outputs/repairs-summary_10-07-2019.csv')
repair_subset <- repairs_data %>%
filter(str_detect(Case.Note, '\\.*foll*.*') |
str_detect(Case.Note, '\\.*leak*.*') |
str_detect(Case.Note, '\\.*paint*.*')|
str_detect(Case.Note, '\\.*plaster*.*')|
str_detect(Case.Note, '\\.*cabinet*.*')|
str_detect(Case.Note, '\\.*radiat*.*')|
str_detect(Case.Note, '\\.*window*.*')|
str_detect(Case.Note, '\\.*mold*.*')|
str_detect(Case.Note, '\\.*door*.*')|
str_detect(Case.Note, '\\.*refrigerat*.*')|
str_detect(Case.Note, '\\.*exterminat*.*')
) %>%
mutate(Compliance.Note.Date = as.Date(as.Date(Compliance.Note.Date, format="%d-%b-%y")), format="%b-%d-%Y") %>%
select(Full.Name, Development.Name, Compliance.Note.Date, Case.Note, Note_category) %>%
arrange(Full.Name, Compliance.Note.Date)
repair_subset <- repair_subset[3:nrow(repair_subset),]
repair_subset$ncount <- NA
repair_subset$ncount[1] <- 1
for (i in 2:length(repair_subset$Full.Name)) {
if(repair_subset$Full.Name[i] == repair_subset$Full.Name[i-1]){
repair_subset$ncount[i] <- repair_subset$ncount[i-1] + 1
} else {
repair_subset$ncount[i] <- 1
}
}
repair_subset <- repair_subset %>%
select(Full.Name, Development.Name, ncount, Compliance.Note.Date, Case.Note, Note_category) %>%
mutate(Case.Note = tolower(Case.Note)) %>%
mutate(Case.Note = str_replace_all(Case.Note, 'follow\\s?\\-?\\s?up?:?;?\\s?-?\\s?,?\\s?', ''))
repair_subset$compare <- NA
repair_subset$compare[1] <- NA
for (i in 2:length(repair_subset$Full.Name)) {
if(repair_subset$ncount[i] != 1){
repair_subset$compare[i] <- levenshteinSim(repair_subset$Case.Note[i-1], repair_subset$Case.Note[i])
} else {
repair_subset$compare[i] <- NA
}
}
